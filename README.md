# Real-Estate-Property-Data-Analysis-and-Price-Prediction-Project
## Table of Contents
- [Overview](#overview)
- [Dataset Details](#dataset-details)
- [Data Preparation](#data-preparation)
- [Exploratory Analysis](#exploratory-analysis)
- [Model Building](#model-building)
- [Evaluation Metrics](#evaluation-metrics)
- [Future Price Predictions](#future-price-predictions)
- [Conclusion](#conclusion)
- [Tools and Technologies Used](#tools-and-technologies-used)
- [Requirements](#requirements)
- [Acknowledgements](#acknowledgements)

  ## Overview
This project focuses on analyzing and predicting housing prices using Databricks, 
PySpark, and Spark SQL. The dataset includes various features related to housing, 
such as location, property type, area, and price category. The main goal is to 
preprocess the data, perform feature engineering, and build a predictive model to 
estimate housing prices.

## Dataset Details
The dataset includes information about various properties listed for sale. It features property details, pricing, city, province and location information.

### Attributes Include:
- **property_id**: Identifier for the property.
- **location_id**: Identifier for the location.
- **price**: The listed price of the property.
- **property_type**: Type of property (e.g., apartment, house).
- **location**: The property's location (e.g., neighborhood).
- **city**: City of the property.
- **province_name**: Province where the property is located.
- **latitude**: Latitude coordinate.
- **longitude**: Longitude coordinate.
- **baths**: Number of bathrooms.
- **bedrooms**: Number of bedrooms.
- **area**: Area size of the property.
- **purpose**: Listing purpose (e.g., sale, rent).
- **date_added**: Date when the listing was posted.
- **agency**: Real estate agency managing the property.
- **agent**: Agent responsible for the property.
- **Area Type**: Measurement type (e.g., Marla).
- **Area Size**: Size of the area.
- **Area Category**: Category of area size.

## Data Preparation
Data preparation involves:
- **Handling Missing Values**: Addressing null values in critical columns.
- **Feature Engineering**: Creating new features such as price categories, age of property, and location popularity.
- **Encoding Categorical Variables**: Converting categorical features into numerical values using `StringIndexer` and `OneHotEncoder`.
- **Scaling Numerical Features**: Standardizing numerical features for modeling.

## Exploratory Analysis
EDA is performed to understand data distributions and relationships:
- Visualizations include price distributions, trends over time, and comparisons by property type and location.
- Outlier detection and removal to clean the data.

## Model Building
The following models are employed for predicting house prices:
- **Linear Regression**: For baseline performance and interpretability.

## Evaluation Metrics
Model performance is assessed using:
- **Root Mean Squared Error (RMSE)**
- **Mean Absolute Error (MAE)**
- **Mean Squared Error (MSE)**

Evaluation includes visual comparisons of predicted vs. actual prices.

## Future Price Predictions
The trained models are applied to prices for hypothetical scenarios, showcasing the modelâ€™s capability to predict future property values based on new and specific characteristics..

## Conclusion
The project successfully demonstrated the process of analyzing and predicting 
housing prices using Databricks, PySpark, and Spark SQL. The final model provided 
valuable insights and predictions for housing prices. Future steps include further 
tuning of the model, adding more features, and exploring different machine learning 
algorithms to improve accuracy.

## Tools and Technologies Used
- **Databricks Community Edition**: Cloud-based platform used for development and execution of Spark jobs.
- **Apache Spark**: Unified analytics engine for large-scale data processing.
- **PySpark**: Python API for Spark, used for handling big data processing and machine learning.
- **Spark SQL**: Component of Spark used for querying data using SQL.

*Note: All the libraries mentioned are available in Databricks Community Edition. You can import them directly as needed.*

## Requirements
- Python 3.6+
- PySpark
- Databricks Community Edition

## Acknowledgements
Thanks to the [InternnCraft]([https://www.linkedin.com/company/your-institution-link](https://www.linkedin.com/company/internncraft)) platform for the opportunity to work on this project. And also thanks to thw whole data community for their resources and support, and to Databricks for providing the platform.
